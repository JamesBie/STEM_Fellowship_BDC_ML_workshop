{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any machine learning problem can be assigned one of two broad classifications: Supervised learning and Unsupervised learning.\n",
    "\n",
    "Supervised learning is where you have input variables $x$ and an output variable $y$ and you use an algorithm to learn the mapping function from the input to the output. $y$=$f(x)$\n",
    "The variable types can be:\n",
    "1. Numerical, real number measurements (usually quantitative).\n",
    "2. Categorical, from a discrete set (often qualitative). E.g. {Spam, Not-spam}.\n",
    "3. Ordinal, from a discrete set, without metric relation, but allows ranking. E.g. {first, second, third}\n",
    "\n",
    "It is called supervised learning because the process of an algorithm learning from the training dataset can be thought of as a teacher supervising the learning process. We know the correct answers, the algorithm iteratively makes predictions on the training data and is corrected by the teacher. Learning stops when the algorithm achieves an acceptable level of performance.\n",
    "\n",
    "Supervised learning problems can be further grouped into:\n",
    "\n",
    "* __Regression__: A regression problem is when the output variable is a real value, such as “dollars” or “weight”.\n",
    "* __Classification__: A classification problem is when the output variable is a category, such as “red” or “blue” or “disease” and “no disease”.\n",
    "\n",
    "Now, we will dive into Least-squares solution method for Linear Regression, Logistic Regression, and Support Vector Machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least-Squares Method\n",
    "\n",
    "   The learning algorithm takes a training set and outputs $h$.<br>\n",
    "    Hypothesis function $\\hat{y}$ represented as $h_\\theta(x) = \n",
    "          \\theta_0 + \\theta_1x$,<br>\n",
    "    $\\theta_i$: parameters<br>\n",
    "    $\\theta_0$: $y$-intersect<br>\n",
    "    $\\theta_1x$: gradient<br>\n",
    "    $\\alpha$: learning rate (greater = more aggressive)<br>\n",
    "    \n",
    "   The squared error cost function measures the accuracy of the \n",
    "    hypothesis using the average difference of each hypothesis taken\n",
    "    from $(x_i, y_i)$:<br><br> $J(\\theta_0, \\theta_1) = \\dfrac {1}{2m} \\displaystyle \n",
    "    \\sum_{i=1}^m \\left ( \\hat{y_{i}}- y_{i} \\right)^2 = \\dfrac \n",
    "    {1}{2m} \\displaystyle \\sum_{i=1}^m \\left (h_\\theta (x_{i}) \n",
    "    - y_{i} \\right)^2$\n",
    "\n",
    "   The mean of the squares is halved for convencience of computing the \n",
    "    gradient descent, as the derivative term of the square function will\n",
    "    cancil out the 1/2 term. The goal is to minimise $J(\\theta_0, \\theta_1)$. The lowest \n",
    "    value for $J(\\theta_1)$ is selected, which will return the \n",
    "    least difference (best fit).\n",
    "    \n",
    "    \n",
    "\n",
    "![Linear regression of Wikipedia](https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg)\n",
    "\n",
    "### Gradient Descent:\n",
    "\n",
    "Gradient Descent: find the quickest path to the local optimum. \n",
    "If univariate, there will be just one global optimum. This is used to\n",
    "    estimate the parameters in the hypothesis function.\n",
    "\n",
    "   Repeat until convergence:<br>$\\theta_j := \\theta_j - \\alpha\\frac {\\partial}{\\partial\\theta_j} J(\\theta_0, \\theta_1)$\n",
    "\n",
    "\n",
    "   Translates to:\n",
    "<br>$\\theta_0 := \\theta_0 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m}(h_\\theta(x_{i}) - y_{i})$\n",
    "\n",
    "$\\theta_1 := \\theta_1 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m}((h_\\theta(x_{i}) - y_{i})x_i)$\n",
    "\n",
    "   The derivative refers to the direction taken by the gradient descent \n",
    "    (i.e. positive or negative slope direction).\n",
    "\n",
    "   Need to simultaneously update $\\theta_0$, $\\theta_1$..., \n",
    "    $\\theta_n$ by assigning the computed gradiant descents for \n",
    "    $j$=0,$j$=1...,$j$=n to each variable at the same time. If $\\theta_0$ is \n",
    "    updated before $\\theta_1$, the second computation will be using the newly \n",
    "    assigned value of $\\theta_0$.\n",
    "\n",
    "   With fixed $\\alpha$, the derivative will naturally decrease, \n",
    "    taking smaller steps to reach the convergence. $\\alpha$ can take \n",
    "    too many steps to converge if too low, or alternatively can \n",
    "    overshoot and diverge if too high. If already at convergence, \n",
    "    the derivative will be treated as 0 and no more calculations \n",
    "    will be made. \n",
    "\n",
    "Let's dive into the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA on Breast Cancer Dataset (TODO: Implement)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "### Overview\n",
    "\n",
    "Sigmoid function: $h_\\theta(x) = g(\\theta^Tx), \\text{ where } \n",
    "  g(z) = \\frac{1}{1+e^{-z}}$ \\text{ and } $z: \\mathbb{R}$\n",
    "\n",
    "  So, $h_\\theta^{(x)} = \\frac{1}{1+e^{-\\theta^Tx}}$\n",
    "\n",
    "  Interpretation: $h_\\theta(x)$ = 0.7 = 70\\% chance of positive outcome.\n",
    "\n",
    "  $h_\\theta(x) = P(y=1|x;\\theta)$ i.e. the probability that y=1, given x\n",
    "  parameterised by $\\theta$.\n",
    "\n",
    "  $P(y=0|x;\\theta) + P(y=1|x;\\theta) = 1$\n",
    "\n",
    "  Predicts $y=1$ when $h_\\theta(x) \\geq 0.5$, or when $\\theta^Tx \\geq 0$\n",
    "\n",
    "  Decision boundaries can be linear and non-linear. They are defined\n",
    "  by the chosen theta.\n",
    "\n",
    "### Cost Functions\n",
    "\n",
    "Using logistic regression cost function returns a non-convex function: not\n",
    "  guaranteed to converge to global minimum.\n",
    "\n",
    "  $J(\\theta) = \\frac{1}{m} \\displaystyle\\sum_{i=1}^{m} \\text{Cost}\n",
    "  (h_\\theta(x^{(i)}),y^{(i)})$\n",
    "  \n",
    "  Cost$(h_\\theta(x^{(i)}, y^{(i)}) = \\begin{cases}\n",
    "    -\\log(h_\\theta(x)) \\text{ if } y=1\\\\\n",
    "    -\\log(1-h_\\theta(x)) & \\text{if } y=0 \\end{cases}$\n",
    "\n",
    "  If $y=1, h_\\theta(x)\\rightarrow0$ pays a higher cost.\\\\ \n",
    "  If $y=0, h_\\theta(x)\\rightarrow1$ pays a higher cost.\n",
    "\n",
    "  Simplified: Cost$(h_\\theta(x),y) = -y\\log(h_\\theta(x)) \n",
    "  - (1-y)\\log(1-h_\\theta(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If $y=1$, the second half of the cost function is ignored.<br>\n",
    "  If $y=0$, the first half of the cost function is ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This method is derived from maximum likelihood estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Gradient Descent:\n",
    "\n",
    "$J(\\theta) = -\\frac{1}{m}[\\displaystyle\\sum_{i=1}^m y^{(i)}\\log h_\\theta(x^{(i)}) + (1y^{(i)})\\log(1h_\\theta(x^{(i)}))]$ $\\min_\\theta J(\\theta):$\n",
    "\n",
    " $\\text{Repeat} \\{\\hspace{1em} \\theta_j := \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)\\\\\n",
    "  \\hspace{1em} \\}  \\hspace{1em}$ (simultaneously update all $\\theta_j$) \n",
    "\n",
    " $\\frac{\\partial}{\\partial\\theta_j}J(\\theta) = \\displaystyle\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$\n",
    "\n",
    "   The difference between linear and logistic regression gradient descent is that the definition of $h_\\theta^{(x)}$ is now equal to \n",
    "    $\\frac{1}{1+e^{-\\theta^Tx}}$.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
